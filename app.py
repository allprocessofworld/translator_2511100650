import streamlit as st
import streamlit.components.v1 as components
import deepl
from googleapiclient.discovery import build
import pysrt
import io
import zipfile
import json
import re
import html
from collections import OrderedDict

# --- [UI ì„¤ì •] í˜ì´ì§€ ì œëª© ë° ë ˆì´ì•„ì›ƒ ---
st.set_page_config(page_title="ğŸ“š í—ˆìŠ¬í”Œë ˆì´ ìë™ ë²ˆì—­ê¸°", layout="wide")

# --- [ì–¸ì–´ ì„¤ì •] (ì‚¬ìš©ì ìš”ì²­ 1~7ë²ˆ ë°˜ì˜) ---
# is_original: ë²ˆì—­í•˜ì§€ ì•Šê³  ì›ë³¸ ì˜ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ì–¸ì–´ë“¤
TARGET_LANGUAGES = OrderedDict({
    "ko": {"name": "í•œêµ­ì–´", "code": "KO", "use_google": False},
    "el": {"name": "ê·¸ë¦¬ìŠ¤ì–´", "code": "EL", "use_google": True},
    "nl": {"name": "ë„¤ëœë€ë“œì–´", "code": "NL", "use_google": False},
    "no": {"name": "ë…¸ë¥´ì›¨ì´ì–´", "code": "NB", "use_google": False},
    "da": {"name": "ë´ë§ˆí¬ì–´", "code": "DA", "use_google": False},
    "de": {"name": "ë…ì¼ì–´", "code": "DE", "use_google": False},
    "ru": {"name": "ëŸ¬ì‹œì•„ì–´", "code": "RU", "use_google": True},
    "mr": {"name": "ë§ˆë¼í‹°ì–´", "code": "MR", "use_google": True},
    "ms": {"name": "ë§ë ˆì´ì–´", "code": "MS", "use_google": True},
    "vi": {"name": "ë² íŠ¸ë‚¨ì–´", "code": "VI", "use_google": False},
    "bn": {"name": "ë²µê³¨ì–´", "code": "BN", "use_google": True},
    "sv": {"name": "ìŠ¤ì›¨ë´ì–´", "code": "SV", "use_google": False},
    "es": {"name": "ìŠ¤í˜ì¸ì–´", "code": "ES", "use_google": False},
    "sk": {"name": "ìŠ¬ë¡œë°”í‚¤ì•„ì–´", "code": "SK", "use_google": True},
    "ar": {"name": "ì•„ëì–´", "code": "AR", "use_google": True},
    
    # [ê°œì„  2~3] ì•„ëì–´ ì•„ë˜ ì˜ì–´(ë¯¸êµ­, ì•„ì¼ëœë“œ) ì¶”ê°€
    "en-US": {"name": "ì˜ì–´ (ë¯¸êµ­)", "code": "en", "use_google": False, "is_original": True},
    "en-IE": {"name": "ì˜ì–´ (ì•„ì¼ëœë“œ)", "code": "en", "use_google": False, "is_original": True},
    "en-GB": {"name": "ì˜ì–´ (ì˜êµ­)", "code": "en", "use_google": False, "is_original": True},
    
    # [ê°œì„  4~6] ì˜¤ìŠ¤íŠ¸ë ˆì¼ë¦¬ì•„, ì¸ë„, ìºë‚˜ë‹¤ ì„¤ì •
    "en-AU": {"name": "ì˜ì–´ (ì˜¤ìŠ¤íŠ¸ë ˆì¼ë¦¬ì•„)", "code": "en", "use_google": False, "is_original": True},
    "en-IN": {"name": "ì˜ì–´ (ì¸ë„)", "code": "en", "use_google": False, "is_original": True},
    "en-CA": {"name": "ì˜ì–´ (ìºë‚˜ë‹¤)", "code": "en", "use_google": False, "is_original": True},

    "ur": {"name": "ìš°ë¥´ë‘ì–´", "code": "UR", "use_google": True},
    "uk": {"name": "ìš°í¬ë¼ì´ë‚˜ì–´", "code": "UK", "use_google": True},
    "it": {"name": "ì´íƒˆë¦¬ì•„ì–´", "code": "IT", "use_google": True},
    "id": {"name": "ì¸ë„ë„¤ì‹œì•„ì–´", "code": "ID", "use_google": False},
    "ja": {"name": "ì¼ë³¸ì–´", "code": "JA", "use_google": False},
    "zh-CN": {"name": "ì¤‘êµ­ì–´(ê°„ì²´)", "code": "ZH", "use_google": True},
    "zh-TW": {"name": "ì¤‘êµ­ì–´(ë²ˆì²´)", "code": "zh-TW", "use_google": True},
    "cs": {"name": "ì²´ì½”ì–´", "code": "CS", "use_google": True},
    "ta": {"name": "íƒ€ë°€ì–´", "code": "TA", "use_google": True},
    "th": {"name": "íƒœêµ­ì–´", "code": "TH", "use_google": True},
    "te": {"name": "í…”ë£¨êµ¬ì–´", "code": "TE", "use_google": True},
    "tr": {"name": "íŠ€ë¥´í‚¤ì˜ˆì–´", "code": "TR", "use_google": True},
    "pa": {"name": "í€ì¡ì–´", "code": "PA", "use_google": True},
    "pt": {"name": "í¬ë¥´íˆ¬ê°ˆì–´", "code": "PT-PT", "use_google": False},
    "pl": {"name": "í´ë€ë“œì–´", "code": "PL", "use_google": True},
    "fr": {"name": "í”„ë‘ìŠ¤ì–´", "code": "FR", "use_google": False},
    "fi": {"name": "í•€ë€ë“œì–´", "code": "FI", "use_google": True},
    "fil": {"name": "í•„ë¦¬í•€ì–´", "code": "tl", "use_google": True}, # [ê°œì„  7] tl ì½”ë“œë¡œ ìˆ˜ì •
    "hu": {"name": "í—ê°€ë¦¬ì–´", "code": "HU", "use_google": True},
    "hi": {"name": "íŒë””ì–´", "code": "HI", "use_google": False},
})

CHUNK_SIZE = 40 

# --- [ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---
def extract_video_id(url_or_id):
    video_id_regex = r'(?:v=|\/|shorts\/)([0-9A-Za-z_-]{11}).*'
    match = re.search(video_id_regex, url_or_id)
    return match.group(1) if match else url_or_id.strip()

def copy_to_clipboard(text):
    escaped_text = json.dumps(str(text or ""))
    html_code = f"""
    <script>
    function copyToClipboard() {{
        const text = {escaped_text};
        const el = document.createElement('textarea');
        el.value = text;
        document.body.appendChild(el);
        el.select();
        document.execCommand('copy');
        document.body.removeChild(el);
    }}
    </script>
    <button onclick="copyToClipboard()" style="cursor:pointer; padding:5px 10px; border-radius:4px; border:1px solid #ddd; background:#f9f9f9; font-weight:600;">ğŸ“„ Copy</button>
    """
    components.html(html_code, height=45)

def generate_youtube_localizations_json(video_id, translations):
    localizations = {}
    for res in translations:
        ui_key = res['ui_key']
        # í•„ë¦¬í•€ì–´(fil) -> tl ë³€í™˜ì€ ì´ë¯¸ TARGET_LANGUAGES ë‹¨ê³„ì—ì„œ ì²˜ë¦¬ë¨
        final_title = st.session_state.get(f"t1_title_{ui_key}", res['title']) or ""
        final_desc = st.session_state.get(f"t1_desc_{ui_key}", res['desc']) or ""
        
        # YouTube APIìš© ì½”ë“œ ë³´ì • (en-US ë“±ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥)
        api_key = 'tl' if ui_key == 'fil' else ui_key
        localizations[api_key] = { "title": final_title, "description": final_desc }
        
    request_body = { "id": video_id, "localizations": localizations }
    return json.dumps(request_body, indent=2, ensure_ascii=False)

# --- [í•µì‹¬ ë²ˆì—­ ë¡œì§] ---
@st.cache_data(show_spinner=False)
def translate_deepl(_translator, texts, target_lang):
    try:
        if isinstance(texts, list):
            combined_text = "\n".join([str(t).strip() for t in texts])
            res = _translator.translate_text(combined_text, target_lang=target_lang, split_sentences='off', tag_handling='html')
            return res.text.split('\n'), None
        res = _translator.translate_text(texts, target_lang=target_lang, split_sentences='off', tag_handling='html')
        return res.text, None
    except Exception as e: return "", str(e)

@st.cache_data(show_spinner=False)
def translate_google(_google_translator, texts, target_lang, source_lang='en'):
    try:
        # [ê°œì„  7] í•„ë¦¬í•€ì–´(fil) ëŒ€ì‘
        target = 'tl' if target_lang == 'fil' or target_lang == 'tl' else target_lang
        if isinstance(texts, list):
            combined_text = "\n".join([str(t).strip() for t in texts])
            res = _google_translator.translations().list(q=combined_text, target=target, source=source_lang, format='text').execute()
            translated_text = html.unescape(res['translations'][0]['translatedText'])
            return translated_text.split('\n'), None
        res = _google_translator.translations().list(q=texts, target=target, source=source_lang, format='text').execute()
        return html.unescape(res['translations'][0]['translatedText']), None
    except Exception as e: return "", str(e)

# --- [ìë§‰ í¬ë§·íŒ…] ---
def srt_serialise(index, start, end, text):
    def fmt_t(ts): return f"{ts.hours:02d}:{ts.minutes:02d}:{ts.seconds:02d},{ts.milliseconds:03d}"
    return f"{index}\n{fmt_t(start)} --> {fmt_t(end)}\n{text}\n\n"

def sbv_serialise(start, end, text):
    def fmt_t(ts): return f"{ts.hours:01d}:{ts.minutes:02d}:{ts.seconds:02d}.{ts.milliseconds:03d}"
    return f"{fmt_t(start)},{fmt_t(end)}\n{text}\n\n"

def parse_subs_from_content(content, file_type):
    from pysrt import SubRipFile, SubRipItem
    if file_type == "srt":
        return pysrt.from_string(content)
    else:
        subs = SubRipFile()
        blocks = content.strip().replace('\r\n', '\n').split('\n\n')
        for block in blocks:
            parts = block.split('\n', 1)
            if len(parts) == 2:
                tm = re.match(r'(\d+):(\d+):(\d+)\.(\d+),(\d+):(\d+):(\d+)\.(\d+)', parts[0].strip())
                if tm:
                    g = list(map(int, tm.groups()))
                    sub = SubRipItem(); sub.text = html.unescape(parts[1].strip())
                    sub.start.hours, sub.start.minutes, sub.start.seconds, sub.start.milliseconds = g[0], g[1], g[2], g[3]
                    sub.end.hours, sub.end.minutes, sub.end.seconds, sub.end.milliseconds = g[4], g[5], g[6], g[7]
                    subs.append(sub)
        return subs

# --- [Main UI] ---
try:
    YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
    DEEPL_API_KEY = st.secrets["DEEPL_API_KEY"]
    translator_deepl = deepl.Translator(DEEPL_API_KEY)
    translator_google = build('translate', 'v2', developerKey=YOUTUBE_API_KEY)
except Exception as e:
    st.error(f"Secrets ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

st.title("ğŸ“š í—ˆìŠ¬í”Œë ˆì´ ìë™ ë²ˆì—­ê¸° (Vr.260227-Success)")

if 'video_details' not in st.session_state: st.session_state.video_details = None
if 'translation_results' not in st.session_state: st.session_state.translation_results = []

# Task 1: ì˜ìƒ ì •ë³´ ë²ˆì—­
st.header("1. ì˜ìƒ ì œëª© ë° ì„¤ëª…ë€ ë²ˆì—­")
v_input = st.text_input("YouTube ID ë˜ëŠ” URL", key="yt_input_main")

if st.button("1. ì •ë³´ ê°€ì ¸ì˜¤ê¸°"):
    if v_input:
        video_id = extract_video_id(v_input)
        youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)
        request = youtube.videos().list(part="snippet", id=video_id)
        response = request.execute()
        if response.get('items'):
            st.session_state.video_details = response['items'][0]['snippet']
            st.session_state.clean_id = video_id
            st.success("ì˜ìƒ ì •ë³´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

if st.session_state.video_details:
    snippet = st.session_state.video_details
    st.text_area("ì›ë³¸ ì œëª©", snippet['title'], height=70, disabled=True)
    st.text_area("ì›ë³¸ ì„¤ëª…", snippet.get('description', ''), height=150, disabled=True)
    
    if st.button("2. ë‹¤êµ­ì–´ ë²ˆì—­ ì‹¤í–‰"):
        st.session_state.translation_results = []
        prog = st.progress(0)
        lines = snippet.get('description', '').split('\n')
        
        # [ê°œì„  1~6 ë°˜ì˜]
        for idx, (ui_key, lang_data) in enumerate(TARGET_LANGUAGES.items()):
            # [ê°œì„  1] ìˆœìˆ˜ 'ì˜ì–´(en)'ëŠ” ë²ˆì—­ ëª©ë¡ì—ì„œ ì œì™¸ (JSON ì¤‘ë³µ ë°©ì§€)
            if ui_key == "en": continue
            
            # [ê°œì„  2~6] ì›ë³¸ ìœ ì§€ê°€ í•„ìš”í•œ ì˜ì–´ê¶Œ ì–¸ì–´ë“¤ (US, IE, GB, AU, IN, CA)
            if lang_data.get("is_original"):
                t_t = snippet['title']
                t_d = snippet.get('description', '')
            else:
                # ì¼ë°˜ ë‹¤êµ­ì–´ ë²ˆì—­ ì‹¤í–‰
                if lang_data["use_google"]:
                    t_t, _ = translate_google(translator_google, snippet['title'], ui_key)
                    t_d_list, _ = translate_google(translator_google, lines, ui_key)
                    t_d = "\n".join(t_d_list) if t_d_list else ""
                else:
                    t_t, _ = translate_deepl(translator_deepl, snippet['title'], lang_data["code"])
                    t_d_list, _ = translate_deepl(translator_deepl, lines, lang_data["code"])
                    t_d = "\n".join(t_d_list) if t_d_list else ""
            
            st.session_state.translation_results.append({
                "lang_name": lang_data["name"], "ui_key": ui_key,
                "title": t_t or "", "desc": t_d or ""
            })
            prog.progress((idx+1)/len(TARGET_LANGUAGES))
        st.success("ì „ì²´ ë‹¤êµ­ì–´ ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    if st.session_state.translation_results:
        for res in st.session_state.translation_results:
            # [ê°œì„  8] ëª¨ë“  ìµìŠ¤íŒ¬ë” ì—´ê¸°
            with st.expander(f"ğŸ“ {res['lang_name']}", expanded=True):
                st.text_input("ì œëª©", res['title'], key=f"t1_title_{res['ui_key']}")
                st.text_area("ì„¤ëª…", res['desc'], key=f"t1_desc_{res['ui_key']}", height=100)
        
        st.divider()
        # [ê°œì„  9] ë¬¸êµ¬ ë³€ê²½
        st.header("YouTube ì¼ê´„ ì—…ë¡œë“œ (JSON)")
        if st.button("ğŸš€ JSON ìƒì„±"):
            error_langs = []
            for res in st.session_state.translation_results:
                curr_title = st.session_state.get(f"t1_title_{res['ui_key']}", res['title'])
                if len(str(curr_title or "")) > 100: error_langs.append(f"{res['lang_name']}")
            
            if error_langs:
                st.error(f"âŒ ì œëª© 100ì ì´ˆê³¼ ì–¸ì–´: {', '.join(error_langs)}")
            else:
                json_body = generate_youtube_localizations_json(st.session_state.clean_id, st.session_state.translation_results)
                st.code(json_body, language="json")
                copy_to_clipboard(json_body)
                st.markdown("""
                ### **ğŸš€ ì—…ë°ì´íŠ¸ ê°€ì´ë“œ**
                1. ìœ„ ì½”ë“œë¥¼ **Copy** í•˜ì„¸ìš”.
                2. **ğŸ‘‰ [Google YouTube API Explorer](https://developers.google.com/youtube/v3/docs/videos/update?apix=true)** ì ‘ì†
                3. **`part`**: **`localizations`** ë¼ê³  ì…ë ¥
                4. **`Request body`**: ë³µì‚¬í•œ JSON ë¶™ì—¬ë„£ê¸°
                5. **Execute** í´ë¦­!
                """)

st.divider()

# [ê°œì„  10] 3. í•œêµ­ì–´ â–¶ ì˜ì–´ ë²ˆì—­ (Deepl)
st.header("3. í•œêµ­ì–´ â–¶ ì˜ì–´ ë²ˆì—­ (Deepl)")
ck1, ck2 = st.columns(2)
with ck1: up_ko_sbv = st.file_uploader("í•œêµ­ì–´ .sbv ì—…ë¡œë“œ", type=['sbv'], key="up_ko_sbv")
with ck2: up_ko_srt = st.file_uploader("í•œêµ­ì–´ .srt ì—…ë¡œë“œ", type=['srt'], key="up_ko_srt")

if (up_ko_sbv or up_ko_srt) and st.button("ğŸ‡ºğŸ‡¸ í•œêµ­ì–´ â–¶ ì˜ì–´ ë²ˆì—­ ì‹œì‘"):
    target_up = up_ko_sbv if up_ko_sbv else up_ko_srt
    f_type = "sbv" if up_ko_sbv else "srt"
    content = target_up.read().decode("utf-8")
    subs = parse_subs_from_content(content, f_type)
    
    with st.spinner("DeepL ì˜ì–´ ë²ˆì—­ ì¤‘..."):
        texts = [s.text.replace('\n', ' ') for s in subs]
        translated, _ = translate_deepl(translator_deepl, texts, "EN-US")
        
        final_content = []
        for idx, txt in enumerate(translated):
            if idx >= len(subs): break
            if f_type == "sbv":
                final_content.append(sbv_serialise(subs[idx].start, subs[idx].end, str(txt).strip()))
            else:
                final_content.append(srt_serialise(idx+1, subs[idx].start, subs[idx].end, str(txt).strip()))
        
        st.download_button(f"ğŸ“¥ ì˜ì–´ ë²ˆì—­ëœ {f_type.upper()} ë‹¤ìš´ë¡œë“œ", "".join(final_content), file_name=f"Translated_EN.{f_type}")

st.divider()

# Task 4 & 5: ì˜ì–´ ìë§‰ ë‹¤êµ­ì–´ ë²ˆì—­ (Hybrid)
st.header("4. ì˜ì–´ ìë§‰ â–¶ ë‹¤êµ­ì–´ ë²ˆì—­ (Hybrid)")
c1, c2 = st.columns(2)
with c1: up_multi_sbv = st.file_uploader("ì˜ì–´ .sbv", type=['sbv'], key="up_multi_sbv")
with c2: up_multi_srt = st.file_uploader("ì˜ì–´ .srt", type=['srt'], key="up_multi_srt")

def process_subs_hybrid(subs, file_type):
    zip_buf = io.BytesIO()
    original_texts = [s.text.replace('\n', ' ') for s in subs]
    with zipfile.ZipFile(zip_buf, "a", zipfile.ZIP_DEFLATED, False) as zf:
        p_text = st.empty()
        for i, (uk, ld) in enumerate(TARGET_LANGUAGES.items()):
            # ìë§‰ ë²ˆì—­ ë¦¬ìŠ¤íŠ¸ì—ì„œë„ ìˆœìˆ˜ ì˜ì–´(en)ëŠ” êµ³ì´ ìƒì„±í•˜ì§€ ì•ŠìŒ (ì„ íƒì‚¬í•­)
            p_text.text(f"ë²ˆì—­ ì¤‘: {ld['name']}")
            t_l = []
            for j in range(0, len(original_texts), CHUNK_SIZE):
                chunk = original_texts[j:j+CHUNK_SIZE]
                if ld.get("is_original"):
                    res = chunk # ì˜ì–´ê¶Œì€ ë²ˆì—­ ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ
                else:
                    res, _ = translate_google(translator_google, chunk, uk) if ld["use_google"] else translate_deepl(translator_deepl, chunk, ld["code"])
                t_l.extend(res if isinstance(res, list) else [res])
            
            content = []
            for idx, txt in enumerate(t_l):
                if idx >= len(subs): break
                if file_type == "sbv": content.append(sbv_serialise(subs[idx].start, subs[idx].end, str(txt).strip()))
                else: content.append(srt_serialise(idx+1, subs[idx].start, subs[idx].end, str(txt).strip()))
            zf.writestr(f"{ld['name']} ìë§‰.{file_type}", "".join(content))
        p_text.success("ì „ì²´ ë‹¤êµ­ì–´ ë²ˆì—­ ì™„ë£Œ!")
    return zip_buf.getvalue()

if up_multi_sbv and st.button("ğŸš€ SBV ë‹¤êµ­ì–´ ë²ˆì—­ ì‹œì‘"):
    content = up_multi_sbv.read().decode("utf-8")
    subs = parse_subs_from_content(content, "sbv")
    st.download_button("ğŸ“‚ ë²ˆì—­ëœ SBV ZIP ë‹¤ìš´ë¡œë“œ", process_subs_hybrid(subs, "sbv"), "multilingual_sbv.zip")

if up_multi_srt and st.button("ğŸš€ SRT ë‹¤êµ­ì–´ ë²ˆì—­ ì‹œì‘"):
    content = up_multi_srt.read().decode("utf-8")
    subs = parse_subs_from_content(content, "srt")
    st.download_button("ğŸ“‚ ë²ˆì—­ëœ SRT ZIP ë‹¤ìš´ë¡œë“œ", process_subs_hybrid(subs, "srt"), "multilingual_srt.zip")
