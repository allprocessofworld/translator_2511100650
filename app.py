import streamlit as st
import re
from datetime import datetime, timedelta
import requests
import io
import gc
import zipfile
import concurrent.futures 
from pydub import AudioSegment

# --- 1. ê¸°ë³¸ ì„¤ì • ë° í•¨ìˆ˜ ì •ì˜ ---

def parse_srt_time(time_str):
    """SRT ì‹œê°„ ë¬¸ìì—´(00:00:00,000)ì„ ë°€ë¦¬ì´ˆ(ms)ë¡œ ë³€í™˜"""
    time_str = time_str.replace(',', '.')
    t = datetime.strptime(time_str, "%H:%M:%S.%f")
    delta = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second, microseconds=t.microsecond)
    return delta.total_seconds() * 1000

def parse_srt(srt_content):
    """SRT ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    srt_content = srt_content.replace("\r\n", "\n") 
    
    pattern = re.compile(r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n((?:(?!\d+\n).)*)', re.DOTALL)
    matches = pattern.findall(srt_content)
    
    parsed_data = []
    for idx, start, end, text in matches:
        start_ms = parse_srt_time(start)
        end_ms = parse_srt_time(end)
        duration_ms = end_ms - start_ms
        clean_text = text.strip().replace('\n', ' ')
        parsed_data.append({
            'index': int(idx),
            'start_ms': start_ms,
            'end_ms': end_ms,
            'duration_ms': duration_ms,
            'text': clean_text
        })
    return parsed_data

def generate_audio_task(params):
    """ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°œë³„ ì‘ì—… í•¨ìˆ˜ (API í˜¸ì¶œ)"""
    text, voice_id, api_key, segment_idx = params
    
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    headers = {
        "xi-api-key": api_key,
        "Content-Type": "application/json"
    }
    data = {
        "text": text,
        "model_id": "eleven_multilingual_v2",
        "voice_settings": {
            "stability": 0.5,
            "similarity_boost": 0.75
        }
    }
    
    try:
        response = requests.post(url, json=data, headers=headers, timeout=30)
        if response.status_code == 200:
            return (segment_idx, response.content)
        else:
            return (segment_idx, None)
    except Exception as e:
        return (segment_idx, None)

def remove_silence(audio_segment, silence_thresh=-50.0):
    """ì˜¤ë””ì˜¤ ì•ë’¤ ë¬´ìŒ ì œê±°"""
    if len(audio_segment) == 0: return audio_segment
    start_trim = 0
    end_trim = len(audio_segment)
    for i in range(0, len(audio_segment), 10):
        if audio_segment[i:i+10].dBFS > silence_thresh:
            start_trim = i
            break
    for i in range(len(audio_segment)-10, 0, -10):
        if audio_segment[i:i+10].dBFS > silence_thresh:
            end_trim = i + 10
            break
    if start_trim >= end_trim: return audio_segment
    return audio_segment[start_trim:end_trim]

def match_target_duration(audio_segment, target_duration_ms):
    """ì˜¤ë””ì˜¤ ì‹±í¬ ë§ì¶”ê¸°"""
    if len(audio_segment) > 0:
        audio_segment = remove_silence(audio_segment)

    current_duration_ms = len(audio_segment)
    if current_duration_ms == 0:
        return AudioSegment.silent(duration=int(target_duration_ms))

    if current_duration_ms > target_duration_ms:
        speed_factor = current_duration_ms / target_duration_ms
        try:
            refined_audio = audio_segment.speedup(playback_speed=speed_factor)
        except Exception:
            refined_audio = audio_segment
        if len(refined_audio) > target_duration_ms:
            refined_audio = refined_audio[:int(target_duration_ms)]
    else:
        silence_duration = target_duration_ms - current_duration_ms
        silence = AudioSegment.silent(duration=int(silence_duration))
        refined_audio = audio_segment + silence
        
    return refined_audio

# --- 2. Streamlit ì›¹ ì•± UI êµ¬ì„± ---

st.set_page_config(page_title="ì¥í¸ ë‹¤íìš© ì¼ë ˆë¸ë©ìŠ¤ (ìŠ¤ë§ˆíŠ¸ ë¶„í• )", page_icon="âš¡")
st.title("âš¡ ì¥í¸ ë‹¤íìš© ì¼ë ˆë¸ë©ìŠ¤ (ìŠ¤ë§ˆíŠ¸ ë¶„í• )")

st.warning("âš  **ê³ ì† ëª¨ë“œ:** ì²˜ë¦¬ ì†ë„ê°€ 3~4ë°° ë¹ ë¦…ë‹ˆë‹¤. ë°˜ë“œì‹œ **SRT íŒŒì¼ì„ 1ê°œì”©ë§Œ** ì—…ë¡œë“œí•˜ì„¸ìš”.")
st.warning("âš  ë”ë¹™ ìƒì„±ì„ ì‹ ì¤‘í•˜ê²Œ ê²°ì •í•˜ì„¸ìš”. (ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì¦‰ì‹œ ë¹„ìš©ì´ ì°¨ê°ë©ë‹ˆë‹¤.)")

with st.sidebar:
    st.header("ì„¤ì • (Settings)")
    st.markdown("### ë”ë¹™ ìºë¦­í„°ì˜ Voice ID ì…ë ¥")
    voice_id = st.text_input("voice_id_label", value="", label_visibility="collapsed")
    st.error("âš  ëª©ì†Œë¦¬ ìºë¦­í„°ë¥¼ ì‹ ì¤‘í•˜ê²Œ ì…ë ¥í•˜ì„¸ìš”.")
    st.info("ğŸ’¡ Tip: ì˜ì–´ ì›ë¬¸ì„ 20% ì •ë„ ì§§ê²Œ ì••ì¶•í•´ì•¼ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.")
    max_workers = st.slider("ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ (ì†ë„ ì¡°ì ˆ)", min_value=1, max_value=5, value=4)
    st.caption("ê¶Œì¥: 4")
    st.divider() 
    if "ELEVENLABS_API_KEY" in st.secrets:
        api_key = st.secrets["ELEVENLABS_API_KEY"]
        st.success("âœ… API Keyê°€ ì•ˆì „í•˜ê²Œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        api_key = st.text_input("ElevenLabs API Key", type="password")
        st.warning("Secretsì— í‚¤ë¥¼ ë“±ë¡í•˜ë©´ ë§¤ë²ˆ ì…ë ¥í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.")

st.info("â„¹ï¸ 10ë¶„ ë‹¨ìœ„ë¡œ ë¬¸ì¥ì´ ëŠê¸°ì§€ ì•Šê²Œ **ìŠ¤ë§ˆíŠ¸ ë¶„í• **ë˜ì–´ ZIP íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.")
st.warning("SRT íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. ë°˜ë“œì‹œ 'ì™„ë£Œ' ë¬¸êµ¬ê°€ ëœ° ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì„¸ìš”.")

uploaded_files = st.file_uploader("SRT íŒŒì¼ì„ 1ê°œë§Œ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["srt"], accept_multiple_files=True)

if 'generated_zips' not in st.session_state:
    st.session_state.generated_zips = []

if uploaded_files and api_key:
    if st.button(f"ê³ ì† ë³€í™˜ ì‹œì‘ ({len(uploaded_files)}ê°œ íŒŒì¼)"):
        if not voice_id.strip():
            st.error("ğŸš¨ Voice IDë¥¼ ì…ë ¥í•˜ì„¸ìš”!"); st.stop()
        if len(uploaded_files) > 1:
            st.error("ğŸš¨ ë©”ëª¨ë¦¬ ë³´í˜¸ë¥¼ ìœ„í•´ **í•œ ë²ˆì— 1ê°œì”©ë§Œ** ì‘ì—…í•´ì£¼ì„¸ìš”."); st.stop()

        st.session_state.generated_zips = []
        main_progress = st.progress(0)
        status_text = st.empty()

        for file_idx, uploaded_file in enumerate(uploaded_files):
            file_name = uploaded_file.name
            status_text.markdown(f"### ğŸš€ ì²˜ë¦¬ ì¤‘: **{file_name}**...")
            srt_content = uploaded_file.getvalue().decode("utf-8")
            parsed_segments = parse_srt(srt_content)
            
            if not parsed_segments:
                st.error(f"âš ï¸ {file_name}: ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # --- [ìŠ¤ë§ˆíŠ¸ ë¶„í•  ë¡œì§] ---
            chunk_limit_ms = 10 * 60 * 1000  # 10ë¶„
            current_chunk_audio = AudioSegment.empty()
            parts_buffer = [] 
            
            last_segment_end_ms = 0 
            part_number = 1
            
            sub_progress = st.progress(0)
            
            batch_size = max_workers
            total_segments = len(parsed_segments)
            
            for i in range(0, total_segments, batch_size):
                batch_segments = parsed_segments[i : i + batch_size]
                
                tasks = []
                for seg in batch_segments:
                    tasks.append((seg['text'], voice_id, api_key, seg['index']))
                
                batch_results = {}
                with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                    for result in executor.map(generate_audio_task, tasks):
                        idx, audio_bytes = result
                        batch_results[idx] = audio_bytes
                
                for seg in batch_segments:
                    audio_data = batch_results.get(seg['index'])
                    if not audio_data: continue

                    # ê³µë°± ê³„ì‚°
                    silence_gap = seg['start_ms'] - last_segment_end_ms
                    if silence_gap < 0: silence_gap = 0
                    
                    segment_audio = AudioSegment.from_file(io.BytesIO(audio_data), format="mp3")
                    synced_audio = match_target_duration(segment_audio, seg['duration_ms'])
                    
                    # [í•µì‹¬] ìŠ¤ë§ˆíŠ¸ ë¶„í• : ì´ ë¬¸ì¥ì„ ë”í–ˆì„ ë•Œ 10ë¶„ì„ ë„˜ìœ¼ë©´, ë¯¸ë¦¬ ëŠëŠ”ë‹¤.
                    # (ë‹¨, í˜„ì¬ ì²­í¬ê°€ ë¹„ì–´ìˆì§€ ì•Šì„ ë•Œë§Œ)
                    added_duration = int(silence_gap) + len(synced_audio)
                    
                    if (len(current_chunk_audio) + added_duration > chunk_limit_ms) and (len(current_chunk_audio) > 0):
                        # 1. í˜„ì¬ê¹Œì§€ì˜ íŒŒì¼ ì €ì¥
                        part_filename = f"{file_name.replace('.srt', '')}_Part_{part_number:02d}.mp3"
                        part_buffer = io.BytesIO()
                        current_chunk_audio.export(part_buffer, format="mp3")
                        parts_buffer.append((part_filename, part_buffer))
                        
                        # 2. ì´ˆê¸°í™” ë° ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸ë¡œ ì´ë™
                        current_chunk_audio = AudioSegment.empty()
                        part_number += 1
                        gc.collect()
                        
                        # ì¤‘ìš”: ìƒˆ íŒŒì¼ì˜ ì‹œì‘ì ì—ì„œë„ ê³µë°±(silence_gap)ì€ ìœ ì§€ë˜ì–´ì•¼ 
                        # í¸ì§‘ê¸° íƒ€ì„ë¼ì¸ ìƒì—ì„œ ìœ„ì¹˜ê°€ ë§ìŠµë‹ˆë‹¤.
                    
                    # ì˜¤ë””ì˜¤ ì¶”ê°€
                    current_chunk_audio += AudioSegment.silent(duration=int(silence_gap))
                    current_chunk_audio += synced_audio
                    
                    last_segment_end_ms = seg['end_ms']
                    del audio_data, segment_audio, synced_audio
                
                current_progress = min((i + batch_size) / total_segments, 1.0)
                sub_progress.progress(current_progress)
            
            if len(current_chunk_audio) > 0:
                part_filename = f"{file_name.replace('.srt', '')}_Part_{part_number:02d}.mp3"
                part_buffer = io.BytesIO()
                current_chunk_audio.export(part_buffer, format="mp3")
                parts_buffer.append((part_filename, part_buffer))
                del current_chunk_audio
                gc.collect()

            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zip_file:
                for fname, fbtn in parts_buffer:
                    zip_file.writestr(fname, fbtn.getvalue())
            
            zip_filename = file_name.replace(".srt", "_Full_Parts.zip")
            
            st.session_state.generated_zips.append({
                "filename": zip_filename,
                "data": zip_buffer.getvalue()
            })
            
            st.divider()
            main_progress.progress((file_idx + 1) / len(uploaded_files))

        status_text.success("ğŸ‰ ê³ ì† ì¥í¸ ë³€í™˜ ì™„ë£Œ! ZIP íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")

if st.session_state.generated_zips:
    st.markdown("### ğŸ“¥ ì™„ë£Œëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ZIP)")
    for result in st.session_state.generated_zips:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.info(f"ğŸ—‚ï¸ {result['filename']} (ìŠ¤ë§ˆíŠ¸ ë¶„í•  ì™„ë£Œ)")
        with col2:
            st.download_button(
                label="ğŸ“¥ ZIP ë‹¤ìš´ë¡œë“œ",
                data=result["data"],
                file_name=result["filename"],
                mime="application/zip",
                use_container_width=True 
            )
        st.divider()

elif not api_key:
    st.warning("ì™¼ìª½ ì‚¬ì´ë“œë°”ì— API Keyë¥¼ ì…ë ¥í•˜ê±°ë‚˜ Secretsì— ë“±ë¡í•´ì£¼ì„¸ìš”.")
