import streamlit as st
import streamlit.components.v1 as components
import deepl
from googleapiclient.discovery import build
import pysrt
import io
import zipfile
import json
import re
import html
from collections import OrderedDict

# --- [UI ì„¤ì •] í˜ì´ì§€ ì œëª© ë° ë ˆì´ì•„ì›ƒ ---
st.set_page_config(page_title="ğŸ“š í—ˆìŠ¬í”Œë ˆì´ ìë™ ë²ˆì—­ê¸°", layout="wide")

# --- [ì–¸ì–´ ì„¤ì •] ---
TARGET_LANGUAGES = OrderedDict({
    "ko": {"name": "í•œêµ­ì–´", "code": "KO", "use_google": False},
    "el": {"name": "ê·¸ë¦¬ìŠ¤ì–´", "code": "EL", "use_google": True},
    "nl": {"name": "ë„¤ëœë€ë“œì–´", "code": "NL", "use_google": False},
    "no": {"name": "ë…¸ë¥´ì›¨ì´ì–´", "code": "NB", "use_google": False},
    "da": {"name": "ë´ë§ˆí¬ì–´", "code": "DA", "use_google": False},
    "de": {"name": "ë…ì¼ì–´", "code": "DE", "use_google": False},
    "ru": {"name": "ëŸ¬ì‹œì•„ì–´", "code": "RU", "use_google": True},
    "mr": {"name": "ë§ˆë¼í‹°ì–´", "code": "MR", "use_google": True},
    "ms": {"name": "ë§ë ˆì´ì–´", "code": "MS", "use_google": True},
    "vi": {"name": "ë² íŠ¸ë‚¨ì–´", "code": "VI", "use_google": False},
    "bn": {"name": "ë²µê³¨ì–´", "code": "BN", "use_google": True},
    "sv": {"name": "ìŠ¤ì›¨ë´ì–´", "code": "SV", "use_google": False},
    "es": {"name": "ìŠ¤í˜ì¸ì–´", "code": "ES", "use_google": False},
    "sk": {"name": "ìŠ¬ë¡œë°”í‚¤ì•„ì–´", "code": "SK", "use_google": True},
    "ar": {"name": "ì•„ëì–´", "code": "AR", "use_google": True},
    "en-GB": {"name": "ì˜ì–´ (ì˜êµ­)", "code": "EN-GB", "use_google": False},
    "en-AU": {"name": "ì˜ì–´ (ì˜¤ìŠ¤íŠ¸ë ˆì¼ë¦¬ì•„)", "code": "EN-AU", "use_google": False},
    "en-CA": {"name": "ì˜ì–´ (ìºë‚˜ë‹¤)", "code": "EN-CA", "use_google": False},
    "ur": {"name": "ìš°ë¥´ë‘ì–´", "code": "UR", "use_google": True},
    "uk": {"name": "ìš°í¬ë¼ì´ë‚˜ì–´", "code": "UK", "use_google": True},
    "it": {"name": "ì´íƒˆë¦¬ì•„ì–´", "code": "IT", "use_google": True},
    "id": {"name": "ì¸ë„ë„¤ì‹œì•„ì–´", "code": "ID", "use_google": False},
    "ja": {"name": "ì¼ë³¸ì–´", "code": "JA", "use_google": False},
    "zh-CN": {"name": "ì¤‘êµ­ì–´(ê°„ì²´)", "code": "ZH", "use_google": True},
    "zh-TW": {"name": "ì¤‘êµ­ì–´(ë²ˆì²´)", "code": "zh-TW", "use_google": True},
    "cs": {"name": "ì²´ì½”ì–´", "code": "CS", "use_google": True},
    "ta": {"name": "íƒ€ë°€ì–´", "code": "TA", "use_google": True},
    "th": {"name": "íƒœêµ­ì–´", "code": "TH", "use_google": True},
    "te": {"name": "í…”ë£¨êµ¬ì–´", "code": "TE", "use_google": True},
    "tr": {"name": "íŠ€ë¥´í‚¤ì˜ˆì–´", "code": "TR", "use_google": True},
    "pa": {"name": "í€ì¡ì–´", "code": "PA", "use_google": True},
    "pt": {"name": "í¬ë¥´íˆ¬ê°ˆì–´", "code": "PT-PT", "use_google": False},
    "pl": {"name": "í´ë€ë“œì–´", "code": "PL", "use_google": True},
    "fr": {"name": "í”„ë‘ìŠ¤ì–´", "code": "FR", "use_google": False},
    "fi": {"name": "í•€ë€ë“œì–´", "code": "FI", "use_google": True},
    "fil": {"name": "í•„ë¦¬í•€ì–´", "code": "FIL", "use_google": False},
    "hu": {"name": "í—ê°€ë¦¬ì–´", "code": "HU", "use_google": True},
    "hi": {"name": "íŒë””ì–´", "code": "HI", "use_google": False},
})

CHUNK_SIZE = 40 

# --- [ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---

def extract_video_id(url_or_id):
    video_id_regex = r'(?:v=|\/)([0-9A-Za-z_-]{11}).*'
    match = re.search(video_id_regex, url_or_id)
    if match: return match.group(1)
    if len(url_or_id.strip()) == 11: return url_or_id.strip()
    return url_or_id.strip()

def copy_to_clipboard(text):
    escaped_text = json.dumps(text)
    html_code = f"""
    <script>
    function copyToClipboard() {{
        const text = {escaped_text};
        const el = document.createElement('textarea');
        el.value = text;
        document.body.appendChild(el);
        el.select();
        document.execCommand('copy');
        document.body.removeChild(el);
    }}
    </script>
    <button onclick="copyToClipboard()" style="cursor:pointer; padding:5px 10px; border-radius:4px; border:1px solid #ddd; background:#f9f9f9; font-weight:600;">ğŸ“„ Copy</button>
    """
    components.html(html_code, height=45)

# --- [YouTube APIìš© JSON ìƒì„±] ---

def generate_youtube_localizations_json(video_id, translations):
    localizations = {}
    for res in translations:
        ui_key = res['ui_key']
        # ì‚¬ìš©ìê°€ í™”ë©´ì—ì„œ ìˆ˜ì •í•œ ê°’ì„ ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜´
        final_title = st.session_state.get(f"title_{ui_key}", res['title']) or ""
        final_desc = st.session_state.get(f"desc_{ui_key}", res['desc']) or ""
        
        # YouTube API í•„ë“œ ë§¤í•‘
        lang_code = ui_key
        if lang_code == 'fil': lang_code = 'tl'
        
        localizations[lang_code] = {
            "title": final_title,
            "description": final_desc
        }
        
    request_body = {
        "id": video_id,
        "localizations": localizations
    }
    return json.dumps(request_body, indent=2, ensure_ascii=False)

# --- [í•µì‹¬ ë²ˆì—­ ë¡œì§: ë¬¸ë§¥ ìœ ì§€í˜•] ---

@st.cache_data(show_spinner=False)
def translate_deepl(_translator, texts, target_lang):
    try:
        if isinstance(texts, list):
            # ë¬¸ë§¥ ë³´ì¡´ì„ ìœ„í•´ ê°œí–‰ë¬¸ìë¡œ í•©ì³ì„œ ë²ˆì—­
            combined_text = "\n".join([str(t) for t in texts])
            res = _translator.translate_text(combined_text, target_lang=target_lang, split_sentences='off', tag_handling='html')
            translated_list = res.text.split('\n')
            if len(translated_list) != len(texts):
                # ì¤„ ìˆ˜ê°€ ë§ì§€ ì•Šìœ¼ë©´ ì•ˆì „ì„ ìœ„í•´ ê°œë³„ ë²ˆì—­ ì‹œë„
                res_fallback = _translator.translate_text(texts, target_lang=target_lang, split_sentences='off', tag_handling='html')
                return [r.text for r in res_fallback], None
            return translated_list, None
        else:
            res = _translator.translate_text(texts, target_lang=target_lang, split_sentences='off', tag_handling='html')
            return res.text, None
    except Exception as e: return "", str(e)

@st.cache_data(show_spinner=False)
def translate_google(_google_translator, texts, target_lang, source_lang='en'):
    try:
        target = 'tl' if target_lang == 'fil' else target_lang
        if isinstance(texts, list):
            combined_text = "\n".join([str(t) for t in texts])
            res = _google_translator.translations().list(q=combined_text, target=target, source=source_lang, format='text').execute()
            translated_text = html.unescape(res['translations'][0]['translatedText'])
            translated_list = translated_text.split('\n')
            if len(translated_list) != len(texts):
                res_fallback = _google_translator.translations().list(q=texts, target=target, source=source_lang, format='text').execute()
                return [html.unescape(item['translatedText']) for item in res_fallback['translations']], None
            return translated_list, None
        else:
            res = _google_translator.translations().list(q=texts, target=target, source=source_lang, format='text').execute()
            return html.unescape(res['translations'][0]['translatedText']), None
    except Exception as e: return "", str(e)

@st.cache_data(show_spinner=False)
def get_video_details(api_key, raw_video_id):
    try:
        video_id = extract_video_id(raw_video_id)
        youtube = build('youtube', 'v3', developerKey=api_key)
        request = youtube.videos().list(part="snippet", id=video_id)
        response = request.execute()
        if not response.get('items'): return None, "ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return response['items'][0]['snippet'], None
    except Exception as e: return None, str(e)

# --- [ìë§‰ ì§ë ¬í™” ë³´ì •] ---

def to_sbv_format(subrip_file):
    output = []
    for sub in subrip_file:
        start = f"{sub.start.hours:01d}:{sub.start.minutes:02d}:{sub.start.seconds:02d}.{sub.start.milliseconds:03d}"
        end = f"{sub.end.hours:01d}:{sub.end.minutes:02d}:{sub.end.seconds:02d}.{sub.end.milliseconds:03d}"
        output.append(f"{start},{end}\n{sub.text}")
    return "\n\n".join(output)

@st.cache_data(show_spinner=False)
def parse_sbv(file_content):
    subs = pysrt.SubRipFile()
    blocks = file_content.strip().replace('\r\n', '\n').split('\n\n')
    for i, block in enumerate(blocks):
        if not block.strip(): continue
        parts = block.split('\n', 1)
        if len(parts) != 2: continue
        time_str, text = parts
        time_match = re.match(r'(\d+):(\d+):(\d+)\.(\d+),(\d+):(\d+):(\d+)\.(\d+)', time_str.strip())
        if time_match:
            g = list(map(int, time_match.groups()))
            sub = pysrt.SubRipItem(index=i+1)
            sub.start.hours, sub.start.minutes, sub.start.seconds, sub.start.milliseconds = g[0], g[1], g[2], g[3]
            sub.end.hours, sub.end.minutes, sub.end.seconds, sub.end.milliseconds = g[4], g[5], g[6], g[7]
            sub.text = html.unescape(text.strip())
            subs.append(sub)
    return subs if subs else None

# --- [ë‹¤êµ­ì–´ ìë§‰ ìƒì„± ë¡œì§] ---

def process_subtitle_translation(subs, file_type="srt"):
    zip_buffer = io.BytesIO()
    # í…ìŠ¤íŠ¸ ë‚´ ë¶ˆí•„ìš”í•œ ê°œí–‰ ì œê±° í›„ ë¬¸ë§¥ ë²ˆì—­ ì¤€ë¹„
    original_texts = [s.text.replace('\n', ' ') for s in subs]
    
    with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
        progress_text = st.empty()
        sub_progress = st.progress(0)
        
        for i, (ui_key, lang_data) in enumerate(TARGET_LANGUAGES.items()):
            lang_name = lang_data["name"]
            progress_text.text(f"ğŸŒ ë¬¸ë§¥ íŒŒì•… ë²ˆì—­ ì¤‘: {lang_name} ({i+1}/{len(TARGET_LANGUAGES)})")
            
            translated_lines = []
            error_occured = False
            
            for j in range(0, len(original_texts), CHUNK_SIZE):
                chunk = original_texts[j:j+CHUNK_SIZE]
                if lang_data["use_google"]:
                    res, err = translate_google(translator_google, chunk, ui_key)
                else:
                    res, err = translate_deepl(translator_deepl, chunk, lang_data["code"])
                
                if err:
                    st.error(f"âŒ {lang_name} ë²ˆì—­ ì‹¤íŒ¨: {err}")
                    error_occured = True
                    break
                # ë²ˆì—­ ê²°ê³¼ê°€ ë¬¸ìì—´ë¡œ ì˜¤ë©´ ë¦¬ìŠ¤íŠ¸í™” (ì•ˆì „ì¥ì¹˜)
                if isinstance(res, str): res = [res]
                translated_lines.extend(res)
            
            if not error_occured:
                temp_subs = pysrt.SubRipFile()
                for idx, t_text in enumerate(translated_lines):
                    if idx >= len(subs): break
                    new_item = pysrt.SubRipItem(
                        index=idx + 1, 
                        start=subs[idx].start, 
                        end=subs[idx].end, 
                        text=str(t_text).strip()
                    )
                    temp_subs.append(new_item)
                
                file_ext = "sbv" if file_type == "sbv" else "srt"
                filename = f"{lang_name} ìë§‰.{file_ext}" # í•œê¸€ íŒŒì¼ëª… ì ìš©
                
                # í‘œì¤€ ê·œê²© ì¡°ë¦½: ë¸”ë¡ ê°„ ë¹ˆ ì¤„(\n\n) ìœ ì§€
                if file_type == "sbv":
                    content = to_sbv_format(temp_subs)
                else:
                    # str(item)ì€ pysrtì—ì„œ index\nTime\nText\n í˜•íƒœë¥¼ ë°˜í™˜í•¨
                    content = "\n".join([str(item) for item in temp_subs])
                
                zip_file.writestr(filename, content)
            
            sub_progress.progress((i + 1) / len(TARGET_LANGUAGES))
            
        progress_text.success("âœ… ëª¨ë“  ì–¸ì–´ ë²ˆì—­ ì™„ë£Œ!")
    return zip_buffer.getvalue()

# --- [Main UI] ---

try:
    if "YOUTUBE_API_KEY" in st.secrets and "DEEPL_API_KEY" in st.secrets:
        YOUTUBE_API_KEY = st.secrets["YOUTUBE_API_KEY"]
        DEEPL_API_KEY = st.secrets["DEEPL_API_KEY"]
        translator_deepl = deepl.Translator(DEEPL_API_KEY)
        translator_google = build('translate', 'v2', developerKey=YOUTUBE_API_KEY)
        st.sidebar.success("âœ… API ì¸ì¦ ì„±ê³µ")
    else:
        st.error("âŒ Streamlit Cloudì˜ Secrets ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
except Exception as e:
    st.error(f"âŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    st.stop()

st.title("ğŸ“š í—ˆìŠ¬í”Œë ˆì´ ìë™ ë²ˆì—­ê¸° (Vr.260226-PRO)")

if 'video_details' not in st.session_state: st.session_state.video_details = None
if 'translation_results' not in st.session_state: st.session_state.translation_results = []
if 'clean_id' not in st.session_state: st.session_state.clean_id = ""

# Task 1: ì˜ìƒ ì •ë³´ ë²ˆì—­
st.header("1. ì˜ìƒ ì œëª© ë° ì„¤ëª…ë€ ë²ˆì—­")
v_input = st.text_input("YouTube ID ë˜ëŠ” URL", key="yt_url_input", placeholder="IDë¥¼ ì…ë ¥í•˜ê±°ë‚˜ URLì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")

if st.button("1. ì •ë³´ ê°€ì ¸ì˜¤ê¸°"):
    if v_input:
        with st.spinner("YouTube ì„œë²„ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            snippet, err = get_video_details(YOUTUBE_API_KEY, v_input)
            if err:
                st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {err}")
            else:
                st.session_state.video_details = snippet
                st.session_state.clean_id = extract_video_id(v_input)
                st.success("ì˜ìƒ ì •ë³´ ë¡œë“œ ì™„ë£Œ")

if st.session_state.video_details:
    snippet = st.session_state.video_details
    st.subheader("ì›ë³¸ ë°ì´í„° í™•ì¸")
    st.text_area("ì›ë³¸ ì œëª©", snippet['title'], height=70, disabled=True)
    st.text_area("ì›ë³¸ ì„¤ëª…", snippet.get('description', ''), height=200, disabled=True)
    
    if st.button("2. ë‹¤êµ­ì–´ ë²ˆì—­ ì‹¤í–‰ (Hybrid)"):
        st.session_state.translation_results = []
        progress_bar = st.progress(0)
        lines = snippet.get('description', '').split('\n')
        
        for idx, (ui_key, lang_data) in enumerate(TARGET_LANGUAGES.items()):
            if lang_data["use_google"]:
                t_title, _ = translate_google(translator_google, snippet['title'], ui_key)
                t_desc_list, _ = translate_google(translator_google, lines, ui_key)
            else:
                t_title, _ = translate_deepl(translator_deepl, snippet['title'], lang_data["code"])
                t_desc_list, _ = translate_deepl(translator_deepl, lines, lang_data["code"])
            
            st.session_state.translation_results.append({
                "lang_name": lang_data["name"],
                "ui_key": ui_key,
                "title": t_title or "",
                "desc": "\n".join(t_desc_list) if t_desc_list else ""
            })
            progress_bar.progress((idx + 1) / len(TARGET_LANGUAGES))
        st.success("ì „ì²´ ì–¸ì–´ ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    if st.session_state.translation_results:
        st.subheader("ë²ˆì—­ ê²°ê³¼ ë° ìˆ˜ë™ ë³´ì •")
        for res in st.session_state.translation_results:
            with st.expander(f"ğŸ“ {res['lang_name']}"):
                col_t1, col_t2 = st.columns([8, 1])
                with col_t1: 
                    new_title = st.text_input("ë²ˆì—­ëœ ì œëª©", res['title'], key=f"title_{res['ui_key']}")
                    t_len = len(new_title) # TypeError í•´ê²°: ì´ˆê¸°ê°’ ë³´ì¥
                    if t_len > 100: st.error(f"âŒ ì œëª© ê¸¸ì´ ì´ˆê³¼: {t_len}/100ì")
                    elif t_len >= 95: st.warning(f"âš ï¸ ì œí•œ ì„ë°•: {t_len}/100ì")
                with col_t2: copy_to_clipboard(new_title)
                
                col_d1, col_d2 = st.columns([8, 1])
                with col_d1: st.text_area("ë²ˆì—­ëœ ì„¤ëª…", res['desc'], key=f"desc_{res['ui_key']}", height=150)
                with col_d2: copy_to_clipboard(res['desc'])
        
        # --- [ë³µêµ¬ëœ ì„¹ì…˜] YouTube ì¼ê´„ ì—…ë¡œë“œ (JSON) ---
        st.divider()
        st.header("3. YouTube ì¼ê´„ ì—…ë¡œë“œ (JSON)")
        if st.button("ğŸš€ ì—…ë¡œë“œìš© JSON ìƒì„±"):
            error_langs = []
            for res in st.session_state.translation_results:
                curr_title = st.session_state.get(f"title_{res['ui_key']}", res['title'])
                if len(curr_title) > 100:
                    error_langs.append(f"{res['lang_name']} ({len(curr_title)}ì)")
            
            if error_langs:
                st.error("âŒ ì œëª©ì´ 100ìë¥¼ ì´ˆê³¼í•˜ëŠ” ì–¸ì–´ê°€ ìˆì–´ JSONì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.write(", ".join(error_langs))
            else:
                json_body = generate_youtube_localizations_json(st.session_state.clean_id, st.session_state.translation_results)
                st.code(json_body, language="json")
                col_j1, col_j2 = st.columns([2, 8])
                with col_j1: copy_to_clipboard(json_body)
                with col_j2: st.info("ë³µì‚¬í•œ JSON ì½”ë“œë¥¼ YouTube API Explorerì˜ Request Bodyì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")
                
                st.markdown("""
                ### **ğŸ’¡ ì¼ê´„ ì—…ë°ì´íŠ¸ íŒ**
                1. ìƒì„±ëœ JSON ì½”ë“œë¥¼ **Copy** í•©ë‹ˆë‹¤.
                2. **[Google YouTube API Explorer](https://developers.google.com/youtube/v3/docs/videos/update?apix=true)** í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.
                3. `part` íŒŒë¼ë¯¸í„°ì— `localizations`ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
                4. `Request body` ì¹¸ì— ë³µì‚¬í•œ ì½”ë“œë¥¼ ë¶™ì—¬ë„£ê³  **Execute**ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!
                """)

st.divider()

# Task 2 & 3: í•œêµ­ì–´ -> ì˜ì–´ ë²ˆì—­
st.header("2. í•œêµ­ì–´ ìë§‰ â–¶ ì˜ì–´ ë²ˆì—­ (High Quality)")
col_a, col_b = st.columns(2)
with col_a: up_sbv_ko = st.file_uploader("í•œêµ­ì–´ .sbv íŒŒì¼ ì—…ë¡œë“œ", type=['sbv'], key="ko_sbv_up")
with col_b: up_srt_ko = st.file_uploader("í•œêµ­ì–´ .srt íŒŒì¼ ì—…ë¡œë“œ", type=['srt'], key="ko_srt_up")

if up_sbv_ko or up_srt_ko:
    if st.button("ğŸ‡ºğŸ‡¸ ê³ í’ˆì§ˆ ì˜ì–´ ë²ˆì—­ ì‹œì‘"):
        f = up_sbv_ko if up_sbv_ko else up_srt_ko
        is_sbv = up_sbv_ko is not None
        content = f.read().decode("utf-8")
        subs = parse_sbv(content) if is_sbv else pysrt.from_string(content)
        
        with st.spinner("DeepL ë¬¸ë§¥ ë¶„ì„ ì¤‘..."):
            texts = [s.text for s in subs]
            translated, _ = translate_deepl(translator_deepl, texts, "EN-US")
            
            temp_subs = pysrt.SubRipFile()
            for i, t in enumerate(translated):
                new_item = pysrt.SubRipItem(index=i+1, start=subs[i].start, end=subs[i].end, text=str(t).strip())
                temp_subs.append(new_item)
            
            final_content = to_sbv_format(temp_subs) if is_sbv else "\n".join([str(s) for s in temp_subs])
            st.download_button("ğŸ“¥ ì˜ì–´ ë²ˆì—­ë³¸ ë‹¤ìš´ë¡œë“œ", final_content, file_name=f"ì˜ì–´ ìë§‰.{('sbv' if is_sbv else 'srt')}")

st.divider()

# Task 4 & 5: ì˜ì–´ -> ë‹¤êµ­ì–´ ë²ˆì—­ (Hybrid)
st.header("4. ì˜ì–´ ìë§‰ â–¶ ë‹¤êµ­ì–´ ë²ˆì—­ (Hybrid)")
c1, c2 = st.columns(2)
with c1: up_sbv_multi = st.file_uploader("ì˜ì–´ .sbv ì—…ë¡œë“œ", type=['sbv'], key="multi_sbv")
with c2: up_srt_multi = st.file_uploader("ì˜ì–´ .srt ì—…ë¡œë“œ", type=['srt'], key="multi_srt")

if up_sbv_multi:
    if st.button("ğŸš€ ë‹¤êµ­ì–´ SBV ë²ˆì—­ ë° ZIP ìƒì„±"):
        content = up_sbv_multi.read().decode("utf-8")
        subs = parse_sbv(content)
        if subs:
            zip_data = process_subtitle_translation(subs, file_type="sbv")
            st.download_button("ğŸ“‚ ë²ˆì—­ëœ SBV ZIP ë‹¤ìš´ë¡œë“œ", zip_data, "ë‹¤êµ­ì–´_SBV_ìë§‰.zip")

if up_srt_multi:
    if st.button("ğŸš€ ë‹¤êµ­ì–´ SRT ë²ˆì—­ ë° ZIP ìƒì„±"):
        content = up_srt_multi.read().decode("utf-8")
        try:
            subs = pysrt.from_string(content)
            zip_data = process_subtitle_translation(subs, file_type="srt")
            st.download_button("ğŸ“‚ ë²ˆì—­ëœ SRT ZIP ë‹¤ìš´ë¡œë“œ", zip_data, "ë‹¤êµ­ì–´_SRT_ìë§‰.zip")
        except Exception as e: st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
